{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages, Libraries, and Constants\n",
    "- Different packages, Libraries\n",
    "\n",
    "- Different constants and parameters\n",
    "\n",
    "## Path to the datasets\n",
    "\n",
    "1. Speech Intent Classification (SIC) Dataset\n",
    " - `emabega` - `ddyo` - `unknown` - `kkono`  - `yimirira` - `mu maaso` \n",
    "\n",
    "2. Datasets\n",
    "- `Augmented train data` - `Original train data` - `Test data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the mfcc json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.mfcc import load_data\n",
    "\n",
    "TRAIN_DATA_PATH = \"json/mfcc_train_data.json\"\n",
    "TEST_DATA_PATH = \"json/mfcc_test_data.json\"\n",
    "\n",
    "train_data = load_data(TRAIN_DATA_PATH)\n",
    "test_data = load_data(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(train_data[\"mfcc\"])\n",
    "y_train = np.array(train_data[\"labels\"])\n",
    "X_test = np.array(test_data[\"mfcc\"])\n",
    "y_test = np.array(test_data[\"labels\"])\n",
    "\n",
    "# Split training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.model import model\n",
    "\n",
    "# Input shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "input_shape\n",
    "\n",
    "model = model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the test data prepared as X_test and y_test\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Calculate accuracy, precision, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(y_test, y_pred_classes)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the training history\n",
    "from packages.model import plot_training_history\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"audio_classification_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(file_path, model):\n",
    "    # Load the audio file\n",
    "    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "    # Extract MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13, n_fft=2048, hop_length=512)\n",
    "    mfcc = mfcc.T\n",
    "\n",
    "    # Ensure the correct shape\n",
    "    mfcc = np.expand_dims(mfcc, axis=-1)\n",
    "    mfcc = np.expand_dims(mfcc, axis=0)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(mfcc)\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "    return predicted_index\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('audio_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = pathlib.Path('Dataset/Train')\n",
    "\n",
    "emabega_file_path = os.path.join(train_data_dir, 'emabega', 'emabega_001.wav')\n",
    "ddyo_file_path = os.path.join(train_data_dir, 'ddyo', 'ddyo_001.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Predict\n",
    "file_path = ddyo_file_path\n",
    "predicted_class = predict(file_path, model)\n",
    "print(f'Predicted Class: {predicted_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERAS_MODEL_PATH = \"model/mfcc_model_1.keras\"\n",
    "model.save(KERAS_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.model import get_model_size\n",
    "\n",
    "# Model size\n",
    "keras_model_size = get_model_size(KERAS_MODEL_PATH, 'KB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
