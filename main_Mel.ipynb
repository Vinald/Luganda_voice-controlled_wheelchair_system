{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages, Libraries, and Constants\n",
    "- Different packages, Libraries\n",
    "\n",
    "- Different constants and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 20:44:51.926355: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-29 20:44:51.960866: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-29 20:44:51.969080: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-29 20:44:51.991933: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-29 20:44:53.033896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from packages.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to the datasets\n",
    "\n",
    "1. Speech Intent Classification (SIC) Dataset\n",
    " - `emabega` - `ddyo` - `unknown` - `kkono`  - `yimirira` - `mu maaso` \n",
    "\n",
    "2. Datasets\n",
    "- `Original train data` - `Test data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.utils import train_data_dir, test_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train commands labels: ['unknown' 'ddyo' 'emabega' 'yimirira' 'mumaaso' 'kkono']\n",
      "Test commands labels: ['unknown' 'ddyo' 'emabega' 'yimirira' 'mumaaso' 'kkono']\n"
     ]
    }
   ],
   "source": [
    "from packages.data_processing import list_directory_contents\n",
    "\n",
    "\n",
    "# Show the structure of the directory\n",
    "train_commands = list_directory_contents(train_data_dir, 'Train')\n",
    "test_commands = list_directory_contents(test_data_dir, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train and validation Datasets\n",
    "\n",
    "- `Creating the Train and Validate Datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.data_processing import create_train_val_audio_dataset\n",
    "\n",
    "\n",
    "# Spilt  and baccth data into train and validation and extract Labels\n",
    "train_ds, val_ds, label_names = create_train_val_audio_dataset(train_data_dir)\n",
    "print(f'Labels: {label_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.data_processing import create_test_audio_dataset\n",
    "\n",
    "\n",
    "# Batch the test dataset\n",
    "test_ds = create_test_audio_dataset(test_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "- `Feature Extraction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.data_processing import preprocess_melspec_audio_datasets\n",
    "\n",
    "\n",
    "# Extract Mel-Spectrograms from the audio files\n",
    "train_mel_spec_ds, val_mel_spec_ds, test_mel_spec_ds = preprocess_melspec_audio_datasets(train_ds, val_ds, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_mel_spec_ds.element_spec)\n",
    "print(val_mel_spec_ds.element_spec)\n",
    "print(test_mel_spec_ds.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_spectrograms = next(iter(train_mel_spec_ds))[0]\n",
    "input_shape = example_spectrograms.shape[1:]\n",
    "print('Input shape:', input_shape)\n",
    "\n",
    "num_labels = len(label_names)\n",
    "print(f'Labels {label_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.model import model\n",
    "\n",
    "\n",
    "# Load an NN model\n",
    "model = model(input_shape, num_labels)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.model import compile_and_train_model\n",
    "\n",
    "\n",
    "# Compile, Train and validate the model\n",
    "history = compile_and_train_model(model, train_mel_spec_ds, val_mel_spec_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.model import plot_training_history\n",
    "\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model performance\n",
    "\n",
    "Run the model on the test set and check the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.model import evaluate_model\n",
    "\n",
    "\n",
    "# Evaluate the model using the test dataset\n",
    "evaluate_model(model, test_mel_spec_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.model import plot_confusion_matrix\n",
    "\n",
    "y_pred = model.predict(test_mel_spec_ds)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "y_true = tf.concat(list(test_mel_spec_ds.map(lambda s,lab: lab)), axis=0)\n",
    "label_names_slice = ['ddyo', 'emabega', 'kkono', 'mumaaso', 'unknown', 'yimirira']\n",
    "\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(y_true, y_pred, label_names_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERAS_MODEL_PATH = \"model/Model_spec_1.keras\"\n",
    "\n",
    "model.save(KERAS_MODEL_PATH)\n",
    "print('Model has been successfully saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.utils import get_and_convert_file_size\n",
    "\n",
    "\n",
    "# Get the size of the trained model\n",
    "keras_model_size = get_and_convert_file_size(KERAS_MODEL_PATH, 'MB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
