{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import pathlib\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = pathlib.Path('Dataset/Train_1')\n",
    "test_data_dir = pathlib.Path('Dataset/Test')\n",
    "\n",
    "train_files = list(train_data_dir.glob('*.wav'))\n",
    "test_files = list(test_data_dir.glob('*.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_directory_tree(root_dir, indent=''):\n",
    "    print(indent + os.path.basename(root_dir) + os.path.sep)\n",
    "    indent += '    '\n",
    "    for item in os.listdir(root_dir):\n",
    "        item_path = os.path.join(root_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print_directory_tree(item_path, indent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_1/\n",
      "    emabega/\n",
      "    mumaaso/\n",
      "    yimirira/\n",
      "    ddyo/\n",
      "    gaali/\n",
      "    kkono/\n"
     ]
    }
   ],
   "source": [
    "print_directory_tree(train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test/\n",
      "    emabega/\n",
      "    mumaaso/\n",
      "    yimirira/\n",
      "    ddyo/\n",
      "    gaali/\n",
      "    kkono/\n"
     ]
    }
   ],
   "source": [
    "print_directory_tree(test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_path, json_path, n_mfcc=13, hop_length=512, n_fft=2048):\n",
    "    data = {\n",
    "        'mappings': [],\n",
    "        'labels': [],\n",
    "        'MFCCs': [],\n",
    "        'files': []\n",
    "    }\n",
    "\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        # check if we are not at the root director\n",
    "        if dirpath is not dataset_path:\n",
    "            # update the mappings\n",
    "            category = dirpath.split(\"/\")[-1]\n",
    "            data['mappings'].append(category)\n",
    "            print(f\"Processing {category}\")\n",
    "\n",
    "            # loop through all the filenames and extract the MFCCs\n",
    "            for f in filenames:\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "                # ensure the audio file is at least 2 second\n",
    "                if len(signal) >= SAMPLE_RATE:\n",
    "                    # ensure the signal is at least 2 second\n",
    "                    signal = signal[:SAMPLE_RATE]\n",
    "\n",
    "                    # extract the MFCCs\n",
    "                    MFCCs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                    data['MFCCs'].append(MFCCs.T.tolist())\n",
    "                    data['labels'].append(i-1)\n",
    "                    data['files'].append(file_path)\n",
    "                    print(f\"{file_path}: {i-1}\")\n",
    "    \n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_dataset(TRAIN_DATASET_PATH, TRAIN_JSON_PATH)\n",
    "    prepare_dataset(TEST_DATASET_PATH, TEST_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfccs_and_labels(root_folder):\n",
    "    mfccs = []\n",
    "    labels = []\n",
    "    \n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            if file_path.endswith('.wav'):\n",
    "                audio, sr = librosa.load(file_path, sr=None)\n",
    "                mfcc = librosa.feature.mfcc(y=audio, sr=sr)\n",
    "                mfccs.append(mfcc.T)\n",
    "                labels.append(os.path.basename(subdir))\n",
    "    \n",
    "    return mfccs, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mfccs, labels = extract_mfccs_and_labels(train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 20)\n",
      "(27, 20)\n",
      "(59, 20)\n",
      "(45, 20)\n",
      "(41, 20)\n",
      "(42, 20)\n",
      "(34, 20)\n",
      "(48, 20)\n",
      "(57, 20)\n",
      "(44, 20)\n",
      "(46, 20)\n",
      "(44, 20)\n",
      "(47, 20)\n",
      "(52, 20)\n",
      "(52, 20)\n",
      "(63, 20)\n",
      "(33, 20)\n",
      "(53, 20)\n",
      "(57, 20)\n",
      "(36, 20)\n",
      "(41, 20)\n",
      "(42, 20)\n",
      "(51, 20)\n",
      "(56, 20)\n",
      "(44, 20)\n",
      "(48, 20)\n",
      "(54, 20)\n",
      "(52, 20)\n",
      "(52, 20)\n",
      "(55, 20)\n",
      "(62, 20)\n",
      "(40, 20)\n",
      "(32, 20)\n",
      "(47, 20)\n",
      "(41, 20)\n",
      "(56, 20)\n",
      "(63, 20)\n",
      "(49, 20)\n",
      "(47, 20)\n",
      "(57, 20)\n",
      "(41, 20)\n",
      "(41, 20)\n",
      "(30, 20)\n",
      "(51, 20)\n",
      "(43, 20)\n",
      "(41, 20)\n",
      "(37, 20)\n",
      "(47, 20)\n",
      "(39, 20)\n",
      "(45, 20)\n",
      "(53, 20)\n",
      "(44, 20)\n",
      "(42, 20)\n",
      "(62, 20)\n",
      "(30, 20)\n",
      "(59, 20)\n",
      "(35, 20)\n",
      "(40, 20)\n",
      "(63, 20)\n",
      "(52, 20)\n",
      "(36, 20)\n",
      "(23, 20)\n",
      "(35, 20)\n",
      "(58, 20)\n",
      "(53, 20)\n",
      "(36, 20)\n",
      "(57, 20)\n",
      "(32, 20)\n",
      "(52, 20)\n",
      "(33, 20)\n",
      "(36, 20)\n",
      "(38, 20)\n",
      "(54, 20)\n",
      "(26, 20)\n",
      "(31, 20)\n",
      "(53, 20)\n",
      "(39, 20)\n",
      "(58, 20)\n",
      "(25, 20)\n",
      "(54, 20)\n",
      "(33, 20)\n",
      "(47, 20)\n",
      "(40, 20)\n",
      "(25, 20)\n",
      "(41, 20)\n",
      "(47, 20)\n",
      "(54, 20)\n",
      "(44, 20)\n",
      "(44, 20)\n",
      "(30, 20)\n",
      "(48, 20)\n",
      "(28, 20)\n",
      "(36, 20)\n",
      "(19, 20)\n",
      "(43, 20)\n",
      "(41, 20)\n",
      "(40, 20)\n",
      "(52, 20)\n",
      "(54, 20)\n",
      "(19, 20)\n",
      "(42, 20)\n",
      "(45, 20)\n",
      "(39, 20)\n",
      "(45, 20)\n",
      "(57, 20)\n",
      "(44, 20)\n",
      "(51, 20)\n",
      "(53, 20)\n",
      "(25, 20)\n",
      "(50, 20)\n",
      "(52, 20)\n",
      "(45, 20)\n",
      "(52, 20)\n",
      "(33, 20)\n",
      "(49, 20)\n",
      "(50, 20)\n",
      "(24, 20)\n",
      "(59, 20)\n",
      "(37, 20)\n",
      "(56, 20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for mfcc in train_mfccs:\n",
    "    print(mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'emabega',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'mumaaso',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'yimirira',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'ddyo',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'gaali',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono',\n",
       " 'kkono']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mfccs = extract_mfccs(test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mfcc in mfccs:\n",
    "#     print(test_data_dir.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
